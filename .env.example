OLLAMA_BASE_URL=http://ollama:11434 # On Docker(Default)
# OLLAMA_BASE_URL=http://localhost:11434 #On Localhost
LLM_MODEL_NAME=gemma3:4b
LLM_TEMPERATURE=0.2
LLM_TIMEOUT=120.0
EMBEDDING_MODEL_NAME=BAAI/bge-m3
EMBEDDING_DEVICE=cpu
RERANKER_MODEL_NAME=BAAI/bge-reranker-v2-m3
CHUNK_SIZE=1100
CHUNK_OVERLAP=200
RETRIEVAL_K=20
RERANK_TOP_N=7
DATASET_PATH=dataset/
DATABASE_PATH=database/
OUTPUT_PATH=output/